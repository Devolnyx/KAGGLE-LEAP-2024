{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages\n",
    "\n",
    "Import all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import librosa\n",
    "from scipy import signal as sci_signal\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.models import efficientnet\n",
    "\n",
    "#import tensorflow as tf\n",
    "\n",
    "import albumentations as albu\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, TQDMProgressBar\n",
    "\n",
    "# import score function of BirdCLEF\n",
    "#sys.path.append('/kaggle/input/birdclef-roc-auc')\n",
    "#sys.path.append('/kaggle/usr/lib/kaggle_metric_utilities')\n",
    "#from metric import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vyacheslav\\AppData\\Local\\Temp\\ipykernel_11564\\1764714236.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = mpl.cm.get_cmap('coolwarm')\n"
     ]
    }
   ],
   "source": [
    "# Import for visualization\n",
    "import matplotlib as mpl\n",
    "cmap = mpl.cm.get_cmap('coolwarm')\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display as lid\n",
    "import IPython.display as ipd\n",
    "#import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration\n",
    "\n",
    "Hyper-paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix seed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 28082015\n"
     ]
    }
   ],
   "source": [
    "class config:\n",
    "    \n",
    "    # == global config ==\n",
    "    SEED = 28082015  # random seed\n",
    "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # device to be used\n",
    "    MIXED_PRECISION = False  # whether to use mixed-16 precision\n",
    "    OUTPUT_DIR = './output/'  # output folder\n",
    "    \n",
    "    # == data config ==\n",
    "    DATA_ROOT = 'E:/PycharmProjects/birdclef24/data'  # root folder\n",
    "    PREPROCESSED_DATA_ROOT = '/kaggle/input/birdclef24-spectrograms-via-cupy'\n",
    "    LOAD_DATA = True  # whether to load data from pre-processed dataset\n",
    "\n",
    "    \n",
    "    # == model config ==\n",
    "    MODEL_TYPE = 'efficientnet_b0'  # model type\n",
    "    \n",
    "    # == dataset config ==\n",
    "    BATCH_SIZE = 256  # batch size of each step\n",
    "    N_WORKERS = 6  # number of workers\n",
    "    \n",
    "    \n",
    "    # == training config ==\n",
    "    FOLDS = 7  # n fold\n",
    "    EPOCHS = 200  # max epochs\n",
    "    LR = 7e-4  # learning rate\n",
    "    WEIGHT_DECAY = 9e-6  # weight decay of optimizer\n",
    "    \n",
    "    # == other config ==\n",
    "    VISUALIZE = True  # whether to visualize data and batch\n",
    "    \n",
    "    \n",
    "print('fix seed')\n",
    "pl.seed_everything(config.SEED, workers=True)\n",
    "\n",
    "CFG = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECA(nn.Module):\n",
    "    def __init__(self, kernel_size=5):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.supports_masking = True\n",
    "        self.conv = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=kernel_size, stride=1, padding=\"same\", bias=False)\n",
    "    def forward(self, inputs):\n",
    "        b, c, s = inputs.shape\n",
    "        \n",
    "        x = torch.mean(inputs, axis = -1)\n",
    "        x = x.view(b, 1, c)\n",
    "        x = self.conv(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = x[:,:,None]\n",
    "        return inputs * x\n",
    "\n",
    "\n",
    "class CausalDWConv1D(nn.Module):\n",
    "    def __init__(self, \n",
    "        kernel_size=17,\n",
    "        dilation_rate=1,\n",
    "        use_bias=False,\n",
    "        in_channels = 64,\n",
    "        out_channels = 32,       \n",
    "        depthwise_initializer='glorot_uniform',\n",
    "        **kwargs):\n",
    "        super().__init__()\n",
    "        #self.causal_pad = tf.keras.layers.ZeroPadding1D((dilation_rate*(kernel_size-1),0),name=name + '_pad')\n",
    "        self.dw_conv = nn.Conv1d(\n",
    "            in_channels, \n",
    "            out_channels, \n",
    "            kernel_size, \n",
    "            stride=1, \n",
    "            padding='same', \n",
    "            dilation=dilation_rate, \n",
    "            groups=out_channels,\n",
    "            bias=False, \n",
    "            padding_mode='zeros')\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.dw_conv(inputs)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Conv1DBlock(nn.Module):\n",
    "    def __init__(self, \n",
    "                 kernel_size=17,\n",
    "                 channels = 32,\n",
    "                 expand_channels = 64,\n",
    "                 drop_rate=0.0,\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = CausalDWConv1D(\n",
    "                        kernel_size=kernel_size,\n",
    "                        dilation_rate=1,\n",
    "                        use_bias=False,\n",
    "                        in_channels = expand_channels,\n",
    "                        out_channels = expand_channels\n",
    "                    )\n",
    "        self.dnn_expand = nn.Linear(in_features = channels, \n",
    "                                    out_features = expand_channels\n",
    "                                     )\n",
    "        self.dnn_project = nn.Linear(in_features = expand_channels, \n",
    "                             out_features = channels\n",
    "                                    )\n",
    "        self.bn = nn.BatchNorm1d(num_features = expand_channels, eps=0.95)\n",
    "        self.eca = ECA()\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        skip = inputs\n",
    "\n",
    "        x = inputs.permute([0,2,1])\n",
    "        x = self.dnn_expand(x)\n",
    "        \n",
    "        x = x.permute([0,2,1])\n",
    "        x = self.act(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.eca(x)\n",
    "        \n",
    "        x = x.permute([0,2,1])\n",
    "        x = self.dnn_project(x)\n",
    "        x = x.permute([0,2,1])\n",
    "\n",
    "        return x + skip\n",
    "\n",
    "\n",
    "class Conv1DModel(nn.Module):\n",
    "    def __init__(self, \n",
    "                 kernel_size=17,\n",
    "                 channels = 32,\n",
    "                 expand_channels = 64,\n",
    "                 drop_rate=0.0,\n",
    "                 num_blocks_in_stage = 3,\n",
    "                 input_len = 32_000*5,\n",
    "                 n_classes = 182\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.stem_conv = nn.Linear(in_features = 1, \n",
    "                                    out_features = channels\n",
    "                                     )\n",
    "        self.stem_bn = nn.BatchNorm1d(num_features = channels, eps=0.95)\n",
    "\n",
    "        self.ConvStage_1 = nn.ModuleList([\n",
    "            Conv1DBlock(kernel_size=kernel_size, channels = channels,expand_channels = expand_channels, drop_rate=drop_rate)\n",
    "                                         for _ in range(num_blocks_in_stage)])\n",
    "        self.PoolStage_1 = nn.AvgPool1d(kernel_size=(4))\n",
    "        \n",
    "        self.ConvStage_2 = nn.ModuleList([\n",
    "            Conv1DBlock(kernel_size=kernel_size, channels = channels,expand_channels = expand_channels, drop_rate=drop_rate)\n",
    "                                          for _ in range(num_blocks_in_stage)])\n",
    "        self.PoolStage_2 = nn.AvgPool1d(kernel_size=(4))\n",
    "\n",
    "        \n",
    "        self.ConvStage_3 = nn.ModuleList([\n",
    "            Conv1DBlock(kernel_size=kernel_size, channels = channels,expand_channels = expand_channels, drop_rate=drop_rate)\n",
    "                                          for _ in range(num_blocks_in_stage)])\n",
    "        self.PoolStage_3 = nn.AvgPool1d(kernel_size=(4))\n",
    "\n",
    "        self.pre_out = nn.Linear(in_features = channels, out_features = n_classes*2)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "        self.out_act = nn.SiLU()\n",
    "        self.out = nn.Linear(in_features = n_classes*2, out_features = n_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        b, s = inputs.shape\n",
    "        x = inputs.view(b, s, 1)\n",
    "        x = self.stem_conv(x)\n",
    "        x = x.permute([0,2,1])\n",
    "        x = self.stem_bn(x)\n",
    "\n",
    "        for block in self.ConvStage_1:\n",
    "            x = block(x)\n",
    "        x = self.PoolStage_1(x)\n",
    "\n",
    "        for block in self.ConvStage_2:\n",
    "            x = block(x)\n",
    "        x = self.PoolStage_2(x)\n",
    "\n",
    "        for block in self.ConvStage_3:\n",
    "            x = block(x)\n",
    "        x = self.PoolStage_3(x)\n",
    "\n",
    "        x = x.mean(axis=2)\n",
    "\n",
    "        x = self.pre_out(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_act(x)\n",
    "        \n",
    "        logits = self.out(x)\n",
    "        probs = self.sigmoid(logits)\n",
    "\n",
    "        return {\n",
    "                \"clipwise_logits_long\": logits,\n",
    "                \"clipwise_pred_long\": probs,\n",
    "            }\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "\n",
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head, dropout):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = nn.MultiheadAttention(n_embd, n_head)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x, q = None):\n",
    "        if q is not None:\n",
    "            X = (q, x, x)\n",
    "        else:\n",
    "            X = (x, x, x)\n",
    "        y = self.sa(*X)\n",
    "        y = y[0]\n",
    "        \n",
    "        x = self.ln1(x + y)\n",
    "        y = self.ffwd(x)\n",
    "        x = self.ln2(x + y)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExctractor(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size = 7, channels=16, expand_channels=32, drop_rate = 0.1, n_features=25):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        self.Scales = nn.ModuleList([nn.Conv1d(in_channels = 1,\n",
    "                                                out_channels = channels,\n",
    "                                                kernel_size = 1,\n",
    "                                                stride=1, \n",
    "                                                padding='same') for _ in range(n_features)])\n",
    "        \n",
    "        self.ConvExt = nn.ModuleList([\n",
    "            Conv1DBlock(kernel_size=kernel_size, channels = channels,expand_channels = expand_channels, drop_rate=drop_rate)\n",
    "                                          for _ in range(n_features)])\n",
    "        self.BNs = nn.ModuleList([nn.BatchNorm1d(60) for _ in range(n_features)])\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 556)\n",
    "        \n",
    "        state_t = x[:, 0:60] - 273\n",
    "        state_q0001 = x[:, 60:120] *1_000\n",
    "        state_q0002 = x[:, 120:180] *1_000\n",
    "        state_q0003 = x[:, 180:240] *1_000\n",
    "        state_u = x[:, 240:300] / 100\n",
    "        state_v = x[:, 300:360] / 100\n",
    "    \n",
    "        state_ps = x[:, 360:361]/ 100_000 - 1\n",
    "        pbuf_SOLIN = x[:, 361:362] / 1000\n",
    "        pbuf_LHFLX = x[:, 362:363] / 1000\n",
    "        pbuf_SHFLX = x[:, 363:364] / 1000\n",
    "        pbuf_TAUX = x[:, 364:365] / 1\n",
    "        pbuf_TAUY = x[:, 365:366] / 1\n",
    "        pbuf_COSZRS = x[:, 366:367] / 1\n",
    "        cam_in_ALDIF = x[:, 367:368] / 1\n",
    "        cam_in_ALDIR = x[:, 368:369] / 1\n",
    "        cam_in_ASDIF = x[:, 369:370] / 1\n",
    "        cam_in_ASDIR = x[:, 370:371] / 1\n",
    "        cam_in_LWUP = x[:, 371:372] / 1000\n",
    "        cam_in_ICEFRAC = x[:, 372:373] / 1\n",
    "        cam_in_LANDFRAC = x[:, 373:374] /1\n",
    "        cam_in_OCNFRAC = x[:, 374:375]  /1\n",
    "        cam_in_SNOWHLAND = x[:, 375:376] / 1\n",
    "    \n",
    "        pbuf_ozone = x[:, 376:436] * 100_000\n",
    "        pbuf_CH4 = x[:, 436:496] * 100_000\n",
    "        pbuf_N2O = x[:, 496:556] * 100_000\n",
    "            \n",
    "        inputs = [\n",
    "                state_t,\n",
    "                state_q0001,\n",
    "                state_q0002,\n",
    "                state_q0003, \n",
    "                state_u,\n",
    "                state_v,\n",
    "    \n",
    "                torch.repeat_interleave(state_ps, 60, dim=-1),\n",
    "                torch.repeat_interleave(pbuf_SOLIN, 60, dim=-1),\n",
    "                torch.repeat_interleave(pbuf_LHFLX, 60, dim=-1),\n",
    "                torch.repeat_interleave(pbuf_SHFLX, 60, dim=-1),\n",
    "                torch.repeat_interleave(pbuf_TAUX, 60, dim=-1),\n",
    "               torch.repeat_interleave(pbuf_TAUY, 60, dim=-1),\n",
    "                torch.repeat_interleave(pbuf_COSZRS, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_ALDIF, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_ALDIR, 60, dim=-1),\n",
    "               torch.repeat_interleave(cam_in_ASDIF, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_ASDIR, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_LWUP, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_ICEFRAC, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_LANDFRAC, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_OCNFRAC, 60, dim=-1),\n",
    "                torch.repeat_interleave(cam_in_SNOWHLAND, 60, dim=-1),\n",
    "    \n",
    "                pbuf_ozone,\n",
    "                pbuf_CH4,\n",
    "                pbuf_N2O\n",
    "        ]\n",
    "\n",
    "        output = []\n",
    "        for i, conv in enumerate(self.ConvExt):\n",
    "            #t = self.BNs[i](inputs[i])\n",
    "            t = inputs[i]\n",
    "            t = t.view(-1, 1, 60)\n",
    "            t = self.Scales[i](t)\n",
    "            output.append(conv(t))\n",
    "\n",
    "        return torch.cat(output, 1)#.permute([0,2,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LEADHead(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = nn.SELU()\n",
    "        self.conv_seq = nn.Conv1d(in_channels = n_embd, out_channels = 6,\n",
    "                                                kernel_size = 1,\n",
    "                                                stride=1, \n",
    "                                                padding='same')\n",
    "        \n",
    "        self.conv_flat = nn.Conv1d(in_channels = n_embd, out_channels = 8,\n",
    "                                                kernel_size = 1,\n",
    "                                                stride=1, \n",
    "                                                padding='same')\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.permute([0,2,1])\n",
    "        \n",
    "        p_seq = self.conv_seq(x)\n",
    "        p_seq = nn.Flatten()(p_seq)\n",
    "    \n",
    "        p_flat = self.conv_flat(x)\n",
    "        p_flat = torch.mean(p_flat, axis = -1)\n",
    "        \n",
    "        return torch.cat([p_seq, p_flat], axis= -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5447, -0.5447, -0.5447,  ..., -0.8126,  1.0072,  0.6713],\n",
       "        [-0.5447, -0.5447, -0.5447,  ..., -0.8126,  1.0072,  0.6713],\n",
       "        [-0.5447, -0.5447, -0.5447,  ..., -0.8126,  1.0072,  0.6713],\n",
       "        ...,\n",
       "        [-0.5447, -0.5447, -0.5447,  ..., -0.8126,  1.0072,  0.6713],\n",
       "        [-0.5447, -0.5447, -0.5447,  ..., -0.8126,  1.0072,  0.6713],\n",
       "        [-0.5447, -0.5447, -0.5447,  ..., -0.8126,  1.0072,  0.6713]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEADHead(32)(torch.ones([8,60,32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 16\n",
    "# block_size = 256\n",
    "# max_iters = 5000\n",
    "# learning_rate = 3e-4\n",
    "# eval_iters = 100\n",
    "# n_embd = 384\n",
    "# n_head = 8\n",
    "# n_layer = 12\n",
    "# dropout = 0.2\n",
    "\n",
    "nn_config = dict(\n",
    "    n_embd = 128,\n",
    "    n_head = 4,\n",
    "    fe_channels = 32, \n",
    "    encoder_layers = 4, \n",
    "    fe_drop_rate = 0.1,\n",
    "    att_drop_rate = 0.2,\n",
    "    n_features = 25\n",
    ")\n",
    "\n",
    "    \n",
    "class LEADModelAtt(nn.Module):\n",
    "    def __init__(self, n_embd = 64, n_head = 4, encoder_layers = 3, fe_channels=16, fe_drop_rate=0.1, att_drop_rate=0.2, n_features = 25):\n",
    "        super().__init__()\n",
    "        self.fe = FeatureExctractor(kernel_size = 7, channels=fe_channels, expand_channels=fe_channels*2, drop_rate = fe_drop_rate, n_features=n_features)\n",
    "        \n",
    "        self.bottleneck = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = n_features*fe_channels, out_channels = n_embd*4, kernel_size = 3, stride=1,  padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(n_embd*4),\n",
    "            \n",
    "            nn.Conv1d(in_channels = n_embd*4, out_channels = n_embd*2, kernel_size = 3, stride=1,  padding='same'),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(n_embd*2),\n",
    "            \n",
    "            nn.Conv1d(in_channels = n_embd*2, out_channels = n_embd, kernel_size = 1, stride=1,  padding='same')\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd = n_embd, n_head=n_head, dropout = att_drop_rate) for _ in range(encoder_layers)])\n",
    "        self.head  = LEADHead(n_embd = n_embd)\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, inputs, targets=None):\n",
    "        #B, T = inputs.shape\n",
    "\n",
    "        xf = self.fe(inputs)\n",
    "        xf = self.bottleneck(xf)\n",
    "        x = xf.permute([0,2,1])\n",
    "        \n",
    "        x = self.blocks(x)\n",
    "\n",
    "        out = self.head(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 368])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEADModelAtt(**nn_config)(torch.ones([8, 556])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "class FocalLossBCE(torch.nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            alpha: float = 0.25,\n",
    "            gamma: float = 2,\n",
    "            reduction: str = \"mean\",\n",
    "            bce_weight: float = 1.0,\n",
    "            focal_weight: float = 1.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss(reduction=reduction) #, pos_weight=sample_weights_420)\n",
    "        self.bce_weight = bce_weight\n",
    "        self.focal_weight = focal_weight\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        focall_loss = torchvision.ops.focal_loss.sigmoid_focal_loss(\n",
    "            inputs=logits,\n",
    "            targets=targets,\n",
    "            alpha=self.alpha,\n",
    "            gamma=self.gamma,\n",
    "            reduction=self.reduction,\n",
    "        )\n",
    "        bce_loss = self.bce(logits, targets)\n",
    "        return self.bce_weight * bce_loss + self.focal_weight * focall_loss\n",
    "\n",
    "\n",
    "criterion = FocalLossBCE(focal_weight=5, alpha = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"train_data_sample.parquet\").sample(100000).drop('sample_id', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_y = df.iloc[:, 556:].mean().to_numpy()\n",
    "std_y = df.iloc[:, 556:].std().to_numpy()\n",
    "std_y = np.clip(std_y, 1e-10, 1e3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LEAD_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, augmentation=False, mode='train'):\n",
    "        if mode == 'train':\n",
    "            self.df = df.reset_index(drop=True)\n",
    "        elif mode == 'valid':\n",
    "            self.df = df.reset_index(drop=True)\n",
    "        else:\n",
    "            self.df = df.reset_index(drop=True)\n",
    "        self.mode = mode\n",
    "        self.augmentation = augmentation\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.df.iloc[idx, :556].to_numpy()\n",
    "        y = self.df.iloc[idx, 556:].to_numpy() \n",
    "        y = (y - mean_y) / std_y\n",
    "        \n",
    "        return torch.tensor(x), torch.tensor(y)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-8.4946e-01, -8.4117e-01, -1.0590e+00, -8.3551e-01, -8.2164e-01,\n",
       "         -9.1835e-01, -8.5223e-01, -7.7115e-01, -7.8668e-01, -8.1774e-01,\n",
       "         -8.6398e-01, -9.4047e-01, -1.0246e+00, -1.0578e+00, -1.0390e+00,\n",
       "         -1.0456e+00, -8.9029e-01, -3.4263e-01, -3.8428e-01,  1.7187e-02,\n",
       "         -2.7066e-01, -4.7442e-02, -5.5365e-01, -3.2171e-01, -4.0188e-01,\n",
       "         -4.0085e-01, -3.8172e-01, -2.1434e-01, -1.1706e-01, -1.9239e-01,\n",
       "         -4.9736e-01, -8.4497e-01, -8.7760e-01, -8.1536e-01, -4.2608e-01,\n",
       "         -5.6318e-01, -6.5608e-01,  2.3213e-01, -1.6411e-01, -1.5355e-01,\n",
       "          3.5687e-01,  6.4876e-02,  3.7405e-01,  1.8168e-01,  1.2330e-01,\n",
       "         -3.7806e-01, -6.2132e-01, -7.4627e-01, -8.1018e-01, -5.5426e-01,\n",
       "         -6.8920e-01, -7.0061e-01, -6.6780e-01, -6.5509e-01, -5.6214e-01,\n",
       "         -5.0127e-01, -2.9542e-01, -7.3688e-02,  1.6327e-01,  4.6431e-01,\n",
       "         -2.6445e-06,  2.8567e-07,  2.8671e-07,  2.1952e-07,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -8.7216e-05,  7.2186e-04, -1.5551e-03,\n",
       "          2.4198e-04,  1.5476e-03, -3.6378e-03,  3.6241e-02, -6.1019e-02,\n",
       "          7.4377e-02,  1.7663e-01,  1.8177e-01,  2.0170e-01,  2.3664e-01,\n",
       "          2.1555e-01,  1.9238e-01,  1.7322e-01,  1.8340e-01,  2.3900e-01,\n",
       "          2.5500e-01,  4.0855e-01,  4.3577e-01,  3.0631e-01, -1.7910e-01,\n",
       "         -7.6438e-01, -7.0860e-01, -4.8378e-01, -6.4661e-01, -2.1260e-01,\n",
       "         -6.2715e-03, -1.5647e-01, -2.5312e-01, -2.2326e-01,  1.6617e-01,\n",
       "          2.6764e-01,  2.5499e-01,  2.8969e-01,  4.8797e-01,  2.3610e-01,\n",
       "          1.1787e-01,  5.1936e-02,  1.0786e-01,  2.1694e-01,  3.1101e-01,\n",
       "          4.6426e-01,  5.3493e-01,  4.7632e-01,  4.7042e-01,  3.7779e-01,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  8.1703e-31,  0.0000e+00, -0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  1.4153e-33,  5.6081e-31,\n",
       "          6.6851e-28,  6.3075e-25,  7.3553e-22,  8.2256e-19,  9.6261e-16,\n",
       "          8.6458e-13,  3.3895e-09,  8.2582e-05,  5.0244e-02,  9.9333e-02,\n",
       "          1.1022e-01,  8.1581e-02,  4.0413e-02, -7.4093e-02, -1.0504e-01,\n",
       "         -2.2288e-02,  4.6229e-01,  7.1040e-01,  6.7306e-01,  5.7356e-01,\n",
       "          4.0591e-01, -7.7954e-01, -3.8232e-01, -6.7811e-02, -2.0124e-01,\n",
       "         -1.7146e-01, -7.2324e-02, -7.8326e-02, -1.6838e-01, -1.4727e-01,\n",
       "         -1.4519e-01, -1.3669e-01, -6.1789e-02, -5.3277e-02, -3.6584e-02,\n",
       "         -2.8187e-02, -2.9067e-02, -1.1380e-02,  1.6044e-02,  2.0461e-01,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  1.5237e-05,  1.0820e-05,  1.0197e-05,\n",
       "         -4.9539e-04,  1.9752e-03, -1.4269e-03,  1.3510e-03,  1.2709e-03,\n",
       "          2.7518e-03,  3.1582e-03,  1.5591e-03, -8.8515e-03, -1.7867e-02,\n",
       "         -3.3209e-02, -3.0060e-02,  5.1107e-04, -1.4981e-02, -9.1739e-02,\n",
       "         -2.7114e-01, -6.9394e-01, -8.9168e-01, -7.8146e-01,  2.2486e-01,\n",
       "          4.8120e-01,  2.1992e+00,  2.1273e+00,  1.0394e+00,  9.7861e-01,\n",
       "          6.7269e-01, -7.0147e-01, -2.0770e-01,  2.2010e-01, -3.5382e-01,\n",
       "         -2.6567e-01, -1.3451e-01, -1.3702e-01, -1.6552e-01, -7.8596e-02,\n",
       "         -2.9247e-02, -2.5731e-02, -2.5062e-02, -1.7576e-02, -9.7579e-03,\n",
       "          2.7387e-03,  2.0647e-02,  3.6277e-02,  5.4731e-02,  1.3833e-01,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00, -1.6903e-01,  9.7266e-04, -1.0586e-02,\n",
       "         -3.7082e-03, -4.0523e-03, -6.1556e-02, -8.0662e-02, -6.4562e-02,\n",
       "         -2.1559e-02,  1.1874e-02,  3.3834e-02,  9.2629e-02, -3.9517e-01,\n",
       "          3.9680e-01,  4.6554e-02,  1.8958e-01,  1.7716e-01,  1.1933e-01,\n",
       "          7.7370e-02,  7.5642e-02,  2.4669e-02, -3.4871e-02, -1.1454e-01,\n",
       "         -4.3737e-01, -5.1951e-01,  2.4630e-01,  1.4119e-01, -7.5748e-01,\n",
       "         -2.2430e-01,  5.0642e-01,  1.3308e-01, -4.3935e-01, -4.8448e-01,\n",
       "          2.6743e-01,  2.6204e-01,  4.4164e-01,  2.3430e-01,  3.2915e-01,\n",
       "          3.7262e-01,  2.3854e-01,  1.5193e-01, -9.9496e-03, -1.3253e-01,\n",
       "         -1.3161e-01, -1.4504e-01, -1.7944e-01, -2.8809e-01, -4.3734e-02,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "          0.0000e+00,  0.0000e+00,  9.0669e-02,  3.3399e-03, -6.4921e-01,\n",
       "          7.1646e-01, -4.6819e-01,  1.4406e-01,  1.2579e-02, -2.0242e-02,\n",
       "         -3.4342e-02, -4.9573e-02, -3.5679e-02, -4.6422e-02,  1.0186e+00,\n",
       "         -4.2408e-01, -7.4275e-01,  2.1636e-02, -5.4952e-06, -4.7177e-01,\n",
       "          8.3473e-01, -7.6740e-02,  1.4157e-02,  1.6536e-02,  4.3152e-03,\n",
       "          3.1679e-01,  7.3864e-01,  1.2374e-02, -5.6002e-02,  6.4551e-01,\n",
       "          1.7602e-01, -3.4069e-01,  1.1307e-02,  2.5594e-01,  7.6419e-02,\n",
       "         -2.8445e-02, -2.9491e-02, -4.2607e-01, -8.3950e-01, -4.6245e-02,\n",
       "          2.9904e-01,  2.4276e-01,  8.5960e-02, -1.1940e-02, -1.6296e-02,\n",
       "         -6.6441e-02, -1.1253e-01, -5.5687e-02, -4.9112e-01,  6.6539e-02,\n",
       "         -6.4596e-01,  1.0416e-01, -3.5749e-01, -3.5406e-01, -5.5829e-01,\n",
       "         -5.7552e-01, -7.2620e-01, -5.9923e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEAD_Dataset(df).__getitem__(3)[1].view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2631,  0.2642,  0.2161,  0.1341,  0.1177,  0.5436,  0.8648,  0.7057,\n",
       "          0.8269,  0.7984,  0.8157,  0.5113,  0.6099,  0.6781,  0.5989,  0.6146,\n",
       "          0.6173,  0.5490,  0.3686,  0.4140,  0.5298,  0.4512,  0.5016,  0.3730,\n",
       "          0.4644,  0.4565,  0.4043,  0.5224,  0.6393,  0.5659,  0.5884,  0.4525,\n",
       "          0.2773,  0.1116, -0.0298, -0.3391, -0.4142, -0.5168, -0.5530, -0.5055,\n",
       "         -0.4807, -0.5546, -0.5800, -0.5910, -0.4927, -0.5330, -0.6515, -0.5910,\n",
       "         -0.5682, -0.6745, -0.7100, -0.4314, -0.6006, -0.6802, -0.5908, -0.5121,\n",
       "         -0.5633, -0.5850, -0.5313,  0.3399,  0.0268,  0.0852,  0.0098, -0.0980,\n",
       "         -0.3195, -0.7499, -0.5332, -0.2038,  0.0202,  0.1026,  0.1323,  0.0908,\n",
       "          0.1467,  0.2413,  0.2793,  0.2152,  0.2440,  0.2394,  0.2800,  0.2054,\n",
       "          0.2528,  0.2755,  0.3343,  0.2714,  0.2261,  0.1722,  0.1364,  0.1414,\n",
       "          0.1799,  0.2093,  0.1009,  0.1203,  0.1349,  0.1740,  0.0771,  0.0988,\n",
       "         -0.0686, -0.0794, -0.0502,  0.0797, -0.0374, -0.0865,  0.0363, -0.0318,\n",
       "         -0.0943,  0.0310, -0.0599, -0.0351, -0.0181, -0.0708, -0.0655, -0.0154,\n",
       "         -0.0065,  0.0766, -0.0288,  0.0080, -0.0387,  0.0706, -0.1444, -0.9693,\n",
       "         -0.3348,  1.0833,  1.1414,  1.1673,  0.6828,  0.2470, -0.2738, -0.2125,\n",
       "          0.1400,  0.3202,  0.3975,  0.5863,  0.5638,  0.6132,  0.6052,  0.6058,\n",
       "          0.6109,  0.6128,  0.6948,  0.8007,  0.7589,  0.8608,  0.9319,  1.0051,\n",
       "          1.1286,  1.1371,  1.2752,  1.1697,  1.1929,  1.2291,  1.2712,  1.2143,\n",
       "          1.2679,  1.1003,  0.7565,  0.4638,  0.1484, -0.1205, -0.1549, -0.4261,\n",
       "         -0.3571, -0.4982, -0.4668, -0.5686, -0.5667, -0.5169, -0.7225, -0.6915,\n",
       "         -0.6294, -0.7796, -0.5891, -0.7405, -0.7770, -0.8115, -0.7576, -0.6690,\n",
       "         -0.7247, -0.6174, -0.7135, -0.8663,  0.5016,  0.2744,  0.2833,  0.2209,\n",
       "          0.0506, -0.4189, -0.3093,  0.0231,  0.2800,  0.2380,  0.4347,  0.2927,\n",
       "          0.3749,  0.2757,  0.4105,  0.3209,  0.3010,  0.2658,  0.4233,  0.1161,\n",
       "          0.2631,  0.2562,  0.3023,  0.2559,  0.2814,  0.5632,  0.3523,  0.3463,\n",
       "          0.2459,  0.1788,  0.2426,  0.3560,  0.1361,  0.1826, -0.0112,  0.0715,\n",
       "          0.0483, -0.2095, -0.0747, -0.1835, -0.1200, -0.1005, -0.2048, -0.2603,\n",
       "         -0.2685, -0.2504, -0.2621, -0.3539, -0.1745, -0.2571, -0.1860, -0.2183,\n",
       "         -0.2496, -0.3507, -0.3037, -0.1666, -0.1994, -0.3325, -0.1457, -0.8047,\n",
       "         -0.0163, -0.5736, -0.7361, -1.0212, -1.1673, -1.3714, -0.8049, -0.3123,\n",
       "         -0.2199, -0.0357, -0.0227,  0.0561, -0.1015,  0.0448, -0.0645,  0.0410,\n",
       "          0.1273,  0.1148,  0.1559,  0.0236, -0.0148, -0.0758, -0.0910, -0.1433,\n",
       "         -0.3515, -0.3682, -0.5231, -0.6598, -0.7185, -0.9473, -1.1148, -1.2903,\n",
       "         -1.5330, -1.5531, -1.5603, -1.3490, -1.2429, -1.1550, -1.0015, -0.8489,\n",
       "         -0.7803, -0.7346, -0.6316, -0.5219, -0.5237, -0.4092, -0.5809, -0.5292,\n",
       "         -0.3526, -0.3949, -0.3866, -0.2708, -0.2770, -0.3819, -0.2917, -0.4244,\n",
       "         -0.3376, -0.2790, -0.2836, -0.2940,  0.2277, -1.0264, -0.9430, -0.5748,\n",
       "         -0.2405, -0.0366,  0.0986, -0.1108, -0.4354, -0.7132, -0.7854, -0.9480,\n",
       "         -0.8195, -0.9224, -0.9010, -0.9435, -0.9859, -0.9055, -1.0144, -0.9442,\n",
       "         -1.0014, -0.9652, -1.0860, -1.2522, -1.1323, -1.1668, -1.1466, -1.2296,\n",
       "         -1.1804, -1.0435, -1.0060, -0.8799, -0.6400, -0.4677, -0.1357,  0.0353,\n",
       "          0.2448,  0.4158,  0.5945,  0.4337,  0.5621,  0.6941,  0.6220,  0.7812,\n",
       "          0.7995,  0.7389,  0.7144,  0.6426,  0.7482,  0.7890,  0.6881,  0.6663,\n",
       "          0.7571,  0.7229,  0.7533,  0.7124,  0.6808,  0.7644,  0.8520,  0.4368,\n",
       "          0.1034, -0.1554,  0.2386,  0.0885,  0.2222, -0.0676, -0.1828,  0.0603],\n",
       "        [ 0.0020,  0.1699,  0.1881,  0.1518, -0.0819,  0.0747,  0.4728,  0.5094,\n",
       "          0.5731,  0.6949,  0.7303,  0.6739,  0.5678,  0.6260,  0.5643,  0.5098,\n",
       "          0.5299,  0.4779,  0.5675,  0.4484,  0.3820,  0.4067,  0.3673,  0.4597,\n",
       "          0.3381,  0.5602,  0.5123,  0.4866,  0.3201,  0.0604, -0.2610, -0.4894,\n",
       "         -0.6008, -0.4925, -0.6992, -0.6343, -0.7392, -0.6972, -0.6464, -0.6989,\n",
       "         -0.6171, -0.7045, -0.6344, -0.5953, -0.6828, -0.5745, -0.6608, -0.6717,\n",
       "         -0.6362, -0.5988, -0.5773, -0.6085, -0.5914, -0.6038, -0.6880, -0.5737,\n",
       "         -0.5617, -0.5085, -0.6870,  0.4152, -0.0180,  0.3028,  0.1097, -0.1233,\n",
       "         -0.4110, -0.8122, -1.0191, -0.8432, -0.6821, -0.4692, -0.2130, -0.0859,\n",
       "         -0.0734,  0.0026,  0.1605,  0.1576,  0.1542,  0.2506,  0.1684,  0.2088,\n",
       "          0.2040,  0.2069,  0.1465,  0.2387,  0.1922,  0.0867,  0.0309, -0.0206,\n",
       "         -0.1860, -0.4619, -0.5443, -0.6334, -0.5175, -0.4247, -0.3809, -0.3763,\n",
       "         -0.3076, -0.1628, -0.2242, -0.1253,  0.0816, -0.0576, -0.0739, -0.1713,\n",
       "         -0.0257, -0.0276,  0.0663,  0.0245, -0.0520,  0.0775,  0.0213,  0.0983,\n",
       "          0.1256,  0.0781,  0.1296, -0.0086, -0.0402, -0.0910, -0.0145, -0.7545,\n",
       "         -0.2957,  0.9771,  1.1841,  0.8972,  0.4573,  0.2801, -0.1942, -0.5216,\n",
       "         -0.2756,  0.0460,  0.3462,  0.4537,  0.4830,  0.5146,  0.5656,  0.6117,\n",
       "          0.6210,  0.6316,  0.7611,  0.7911,  0.9682,  0.8333,  0.8320,  1.0986,\n",
       "          1.0640,  1.0197,  1.1135,  1.1302,  1.1621,  0.9270,  0.5904,  0.2749,\n",
       "          0.0541, -0.0997, -0.3597, -0.4093, -0.4610, -0.6582, -0.6830, -0.7361,\n",
       "         -0.7679, -0.7644, -0.8875, -0.8746, -0.7441, -0.9693, -0.8989, -0.9880,\n",
       "         -0.9990, -1.1132, -1.0747, -1.0942, -1.0819, -1.0008, -1.1167, -1.1460,\n",
       "         -1.1423, -1.0656, -1.0234, -1.1544,  0.2312,  0.5876,  0.2435,  0.1294,\n",
       "          0.0641, -0.0361, -0.1646,  0.0193,  0.2745,  0.3593,  0.3567,  0.4052,\n",
       "          0.3445,  0.4010,  0.3702,  0.3180,  0.3000,  0.2664,  0.3701,  0.3963,\n",
       "          0.3348,  0.4182,  0.3078,  0.3595,  0.4959,  0.3697,  0.4234,  0.5042,\n",
       "          0.4939,  0.4549,  0.3905,  0.1729,  0.1009, -0.0566, -0.0634, -0.2518,\n",
       "         -0.2154, -0.2134, -0.2161, -0.2956, -0.2271, -0.3048, -0.3455, -0.2816,\n",
       "         -0.3215, -0.3986, -0.3199, -0.4006, -0.4205, -0.4362, -0.5626, -0.4907,\n",
       "         -0.3700, -0.4130, -0.3217, -0.5397, -0.4114, -0.5634, -0.5344, -0.9337,\n",
       "          0.3023,  0.1903, -0.3275, -0.5417, -0.5644, -0.7359, -0.7720, -0.2962,\n",
       "          0.1049,  0.1875,  0.1940,  0.2611,  0.3420,  0.2239,  0.3563,  0.2115,\n",
       "          0.3461,  0.3272,  0.2673,  0.2160,  0.1102,  0.2615,  0.0854,  0.0887,\n",
       "         -0.0110, -0.0313, -0.1594, -0.2590, -0.4198, -0.5532, -0.5039, -0.5576,\n",
       "         -0.4900, -0.4137, -0.2414, -0.1660, -0.0974, -0.1296,  0.0336, -0.0332,\n",
       "         -0.0307, -0.0381,  0.0103,  0.0526,  0.1873,  0.2261,  0.1581,  0.1748,\n",
       "          0.2028,  0.1604,  0.3206,  0.3170,  0.2206,  0.2530,  0.1606,  0.2558,\n",
       "          0.2396,  0.3083,  0.2860,  0.2742,  0.1531, -0.7841, -0.5858, -0.3428,\n",
       "          0.1138,  0.2747,  0.4609,  0.3860,  0.1063, -0.3207, -0.4668, -0.4672,\n",
       "         -0.6574, -0.6606, -0.7789, -0.7623, -0.6959, -0.8083, -0.9195, -0.8496,\n",
       "         -0.9049, -0.9508, -0.8318, -1.0901, -0.7783, -0.9533, -0.8257, -0.8127,\n",
       "         -0.4892, -0.0974,  0.2827,  0.4563,  0.7575,  0.8751,  0.9356,  0.9997,\n",
       "          0.9792,  0.9835,  1.0047,  1.0469,  0.9112,  1.0046,  0.9482,  0.9757,\n",
       "          0.9230,  0.9531,  1.0173,  0.8967,  0.9489,  0.8746,  0.8050,  0.8340,\n",
       "          1.0608,  0.8845,  0.9510,  0.9293,  0.9567,  0.8446,  1.0268,  0.5757,\n",
       "          0.0518, -0.0391,  0.0873, -0.1789,  0.0513,  0.0317,  0.0574,  0.0343]],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEADModelAtt(**nn_config)(torch.cat([LEAD_Dataset(df).__getitem__(3)[0].view(1, -1), LEAD_Dataset(df).__getitem__(5)[0].view(1, -1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = LEAD_Dataset(df).__getitem__(63)[1]\n",
    "b = LEAD_Dataset(df).__getitem__(9)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([368])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6672)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss()(torch.tensor(np.expand_dims(a, 0)), torch.tensor(np.expand_dims(b, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "#from torcheval.metrics import R2Score \n",
    "from torchmetrics.regression import R2Score\n",
    "metric = R2Score()\n",
    "\n",
    "\n",
    "\n",
    "class LEADModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # == backbone ==\n",
    "        self.backbone = LEADModelAtt(**nn_config).to(config.DEVICE)\n",
    "        \n",
    "\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "        self.metric = R2Score()\n",
    "        \n",
    "        # == record ==\n",
    "        self.validation_step_outputs = []\n",
    "        \n",
    "    def forward(self, images):\n",
    "        return self.backbone(images)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        # == define optimizer ==\n",
    "        model_optimizer = torch.optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.parameters()),\n",
    "            lr=config.LR,\n",
    "            weight_decay=config.WEIGHT_DECAY\n",
    "        )\n",
    "        \n",
    "        # == define learning rate scheduler ==\n",
    "        lr_scheduler = CosineAnnealingWarmRestarts(\n",
    "            model_optimizer,\n",
    "            T_0=config.EPOCHS,\n",
    "            T_mult=1,\n",
    "            eta_min=1e-7,\n",
    "            last_epoch=-1\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'optimizer': model_optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': lr_scheduler,\n",
    "                'interval': 'epoch',\n",
    "                'monitor': 'val_loss',\n",
    "                'frequency': 1\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        # == obtain input and target ==\n",
    "        image, target = batch\n",
    "        image = image.to(self.device).float()\n",
    "        target = target.to(self.device).float()\n",
    "        \n",
    "        # == pred ==\n",
    "        y_pred = self(image)\n",
    "        \n",
    "        # == compute loss ==\n",
    "        train_loss = self.loss_fn(y_pred, target)\n",
    "        \n",
    "        # == record ==\n",
    "        self.log('train_loss', train_loss, True)\n",
    "        \n",
    "        return train_loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        # == obtain input and target ==\n",
    "        image, target = batch\n",
    "        image = image.to(self.device).float()\n",
    "        target = target.to(self.device).float()\n",
    "        \n",
    "        # == pred ==\n",
    "        with torch.no_grad():\n",
    "            y_pred = self(image)\n",
    "            \n",
    "        self.validation_step_outputs.append({\"logits\": y_pred, \"targets\": target})\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self._train_dataloader\n",
    "\n",
    "    def validation_dataloader(self):\n",
    "        return self._validation_dataloader\n",
    "    \n",
    "    def on_epoch_start(self):\n",
    "        print('\\n')\n",
    "\n",
    "    def on_load_checkpoint(self, checkpoint: dict) -> None:\n",
    "        state_dict = checkpoint[\"state_dict\"]\n",
    "        model_state_dict = self.state_dict()\n",
    "        is_changed = False\n",
    "        for k in state_dict:\n",
    "            if k in model_state_dict:\n",
    "                if state_dict[k].shape != model_state_dict[k].shape:\n",
    "                    print(f\"Skip loading parameter: {k}, \"\n",
    "                                f\"required shape: {model_state_dict[k].shape}, \"\n",
    "                                f\"loaded shape: {state_dict[k].shape}\")\n",
    "                    state_dict[k] = model_state_dict[k]\n",
    "                    is_changed = True\n",
    "            else:\n",
    "                print(f\"Dropping parameter {k}\")\n",
    "                is_changed = True\n",
    "\n",
    "        if is_changed:\n",
    "            checkpoint.pop(\"optimizer_states\", None)\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        \n",
    "        # = merge batch data =\n",
    "        outputs = self.validation_step_outputs\n",
    "        \n",
    "        #output_val = nn.Sigmoid()(torch.cat([x['logits'] for x in outputs], dim=0)).cpu().detach()\n",
    "        #output_val = torch.cat([x['logits'] for x in outputs], dim=0).cpu().detach()\n",
    "        #target_val = torch.cat([x['targets'] for x in outputs], dim=0).cpu().detach()\n",
    "        output_val = torch.cat([x['logits'] for x in outputs], dim=0)#.cpu().detach()\n",
    "        target_val = torch.cat([x['targets'] for x in outputs], dim=0)#.cpu().detach()\n",
    "        \n",
    "        \n",
    "        # = compute validation loss =\n",
    "        val_loss = self.loss_fn(output_val, target_val)\n",
    "        # == record ==\n",
    "        print(f\"val_loss: {val_loss}\")\n",
    "        self.log('val_loss', val_loss, True)\n",
    "        \n",
    "        val_loss = val_loss.cpu().detach()\n",
    "\n",
    "    \n",
    "        #output_val = nn.Sigmoid()(output_val).cpu().detach()\n",
    "        output_val = output_val.cpu().detach()\n",
    "        target_val = target_val.cpu().detach()\n",
    "\n",
    "\n",
    "\n",
    "        r2=0\n",
    "        for i in range(368):\n",
    "            r2_i = self.metric(output_val[:, i], target_val[:, i])\n",
    "            if r2_i > 1e-6:\n",
    "                r2 += r2_i\n",
    "        val_score  = r2/ 368\n",
    "            \n",
    "\n",
    "        \n",
    "        # self.metric.update(target_val, output_val)\n",
    "        # val_score = self.metric.compute()\n",
    "        \n",
    "        # target to one-hot\n",
    "        #target_val = torch.nn.functional.one_hot(target_val, len(label_list))\n",
    "        \n",
    "        # = val with ROC AUC =\n",
    "        # gt_df = pd.DataFrame(target_val.numpy().astype(np.float32), columns=label_list)\n",
    "        # pred_df = pd.DataFrame(output_val.numpy().astype(np.float32), columns=label_list)\n",
    "        \n",
    "        # gt_df['id'] = [f'id_{i}' for i in range(len(gt_df))]\n",
    "        # pred_df['id'] = [f'id_{i}' for i in range(len(pred_df))]\n",
    "        \n",
    "        # val_score = score(gt_df.drop(cols_drop_on_val, axis=1), pred_df.drop(cols_drop_on_val, axis=1), row_id_column_name='id')\n",
    "        \n",
    "        print(f\"val_R2: {val_score}\")\n",
    "        \n",
    "        self.log(\"val_R2\", val_score, True)\n",
    "        \n",
    "        # clear validation outputs\n",
    "        self.validation_step_outputs = list()\n",
    "        \n",
    "        return {'val_loss': val_loss, 'val_R2': val_score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CHECKPOINT = False\n",
    "#CHK_PATH = './pretrain_checkpoints/eca_nfnet_l0_fold_0_0.97126.ckpt'\n",
    "\n",
    "\n",
    "def run_training(fold_id, total_df):\n",
    "    print('================================================================')\n",
    "    print(f\"==== Running training for fold {fold_id} ====\")\n",
    "    \n",
    "    # == create dataset and dataloader ==\n",
    "    train_df = total_df[total_df['fold'] != fold_id].drop('fold', axis=1).copy()\n",
    "    valid_df = total_df[total_df['fold'] == fold_id].drop('fold', axis=1).copy()\n",
    "    \n",
    "    print(f'Train Samples: {len(train_df)}')\n",
    "    print(f'Valid Samples: {len(valid_df)}')\n",
    "    \n",
    "  \n",
    "    train_ds = LEAD_Dataset(train_df)\n",
    "    val_ds =  LEAD_Dataset(valid_df)\n",
    "    #val_ds = WaveAllFileDataset(df=valid_df, name_col=\"filepath\", **val_dataset_config)\n",
    "    \n",
    "    \n",
    "    train_dl = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        #num_workers=config.N_WORKERS,\n",
    "        pin_memory=True,\n",
    "        #persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    val_dl = torch.utils.data.DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=config.BATCH_SIZE * 2,\n",
    "        shuffle=False,\n",
    "        #num_workers=config.N_WORKERS,\n",
    "        pin_memory=True,\n",
    "        #persistent_workers=True\n",
    "    )\n",
    "    \n",
    "    # == init model ==\n",
    "    if USE_CHECKPOINT:\n",
    "        model = LEADModel.load_from_checkpoint(CHK_PATH, strict=False)\n",
    "    else:\n",
    "        model = LEADModel()\n",
    "    # == init callback ==\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_loss',\n",
    "                                          dirpath=config.OUTPUT_DIR,\n",
    "                                          save_top_k=1,\n",
    "                                          save_last=True,\n",
    "                                          save_weights_only=True,\n",
    "                                          filename=f\"fold_{fold_id}\",\n",
    "                                          mode='min')\n",
    "\n",
    "    callbacks_to_use = [checkpoint_callback, TQDMProgressBar(refresh_rate=1)]\n",
    "\n",
    "    print(f'trainer')\n",
    "    # == init trainer ==\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=config.EPOCHS,\n",
    "        val_check_interval=1.,\n",
    "        num_sanity_val_steps=0,\n",
    "        callbacks=callbacks_to_use,\n",
    "        enable_model_summary=False,\n",
    "        accelerator=\"gpu\" if torch.cuda.is_available() else 'auto',\n",
    "        deterministic=True,\n",
    "        precision='16-mixed' if config.MIXED_PRECISION else 32,\n",
    "    )\n",
    "    \n",
    "    # == Training ==\n",
    "    trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "    \n",
    "    # == Prediction ==\n",
    "    best_model_path = checkpoint_callback.best_model_path\n",
    "    weights = torch.load(best_model_path)['state_dict']\n",
    "    model.load_state_dict(weights)\n",
    "    \n",
    "    \n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df = train_df[train_df.target<30].reset_index(drop=True)\n",
    "\n",
    "kf = KFold(n_splits=config.FOLDS, shuffle=True, random_state=config.SEED)\n",
    "df['fold'] = 0\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df)):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.EPOCHS = 10\n",
    "#config.LR = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import logging\n",
    "\n",
    "def disable_logging_during_tests():\n",
    "    # Store the current log level to restore it later\n",
    "    original_log_level = logging.getLogger().getEffectiveLevel()\n",
    "\n",
    "    # Set the log level to a higher level, e.g., WARNING or CRITICAL\n",
    "    logging.disable(logging.ERROR)\n",
    "\n",
    "    # Run your tests here\n",
    "\n",
    "    # Restore the original log level after the tests\n",
    "    logging.disable(original_log_level)\n",
    "\n",
    "# Call this function before running your tests\n",
    "disable_logging_during_tests()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================\n",
      "==== Running training for fold 0 ====\n",
      "Train Samples: 85714\n",
      "Valid Samples: 14286\n",
      "trainer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968c4ed614b74d7a95603c7cd4389afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.6069918274879456\n",
      "val_R2: 0.16118839383125305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.5179113149642944\n",
      "val_R2: 0.2442925125360489\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.48237138986587524\n",
      "val_R2: 0.27924787998199463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4769443869590759\n",
      "val_R2: 0.2849314510822296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4639175236225128\n",
      "val_R2: 0.2979210317134857\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4352833926677704\n",
      "val_R2: 0.3267115354537964\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4233962595462799\n",
      "val_R2: 0.33874624967575073\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.417022168636322\n",
      "val_R2: 0.3449324369430542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.41143104434013367\n",
      "val_R2: 0.35035938024520874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.404816210269928\n",
      "val_R2: 0.35782480239868164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3996056020259857\n",
      "val_R2: 0.3627639412879944\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.4095602333545685\n",
      "val_R2: 0.35248953104019165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3929939568042755\n",
      "val_R2: 0.3701450526714325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.38637152314186096\n",
      "val_R2: 0.3770081400871277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.38330891728401184\n",
      "val_R2: 0.37897974252700806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3845108449459076\n",
      "val_R2: 0.3788372576236725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3854481279850006\n",
      "val_R2: 0.37703290581703186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3852533996105194\n",
      "val_R2: 0.37699344754219055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3820417821407318\n",
      "val_R2: 0.3807038962841034\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3795163035392761\n",
      "val_R2: 0.38351428508758545\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3797265887260437\n",
      "val_R2: 0.38284164667129517\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3769436180591583\n",
      "val_R2: 0.3851703703403473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.37291577458381653\n",
      "val_R2: 0.3908238410949707\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.37641677260398865\n",
      "val_R2: 0.38570401072502136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.37051206827163696\n",
      "val_R2: 0.39211270213127136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3885743319988251\n",
      "val_R2: 0.373775452375412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3689335882663727\n",
      "val_R2: 0.39379170536994934\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3688802421092987\n",
      "val_R2: 0.3947659432888031\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.37876036763191223\n",
      "val_R2: 0.38444286584854126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3694678843021393\n",
      "val_R2: 0.3932725787162781\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.36338332295417786\n",
      "val_R2: 0.39931273460388184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val_loss: 0.3777080178260803\n",
      "val_R2: 0.3856325149536133\n",
      "================================================================\n",
      "==== Running training for fold 4 ====\n",
      "Train Samples: 85714\n",
      "Valid Samples: 14286\n",
      "trainer\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499d962f613a400eaf7bae0ec85a591e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 17\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# get validation index\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m#val_idx = list(train_df[train_df['fold'] == f].index)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# main loop of f-fold\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# only training one fold\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m#break\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m#oof_df.to_csv(f\"{config.OUTPUT_DIR}/oof_pred.csv\", index=False)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[50], line 74\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m(fold_id, total_df)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# == Prediction ==\u001b[39;00m\n\u001b[0;32m     73\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m checkpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path\n\u001b[1;32m---> 74\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     75\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(weights)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\n",
      "File \u001b[1;32mE:\\PycharmProjects\\birdclef24\\venv\\Lib\\site-packages\\torch\\serialization.py:997\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    994\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    995\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 997\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    998\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    999\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32mE:\\PycharmProjects\\birdclef24\\venv\\Lib\\site-packages\\torch\\serialization.py:444\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 444\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32mE:\\PycharmProjects\\birdclef24\\venv\\Lib\\site-packages\\torch\\serialization.py:425\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 425\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "selected_folds = [0,4,5]\n",
    "    \n",
    "# training\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "\n",
    "\n",
    "for f in range(config.FOLDS):\n",
    "    \n",
    "    if f not in selected_folds:\n",
    "        continue\n",
    "    \n",
    "    # get validation index\n",
    "    #val_idx = list(train_df[train_df['fold'] == f].index)\n",
    "    \n",
    "    # main loop of f-fold\n",
    "    trainer = run_training(f, df)\n",
    "    \n",
    "\n",
    "    \n",
    "    # only training one fold\n",
    "    #break\n",
    "\n",
    "\n",
    "# for idx, val_score in enumerate(fold_val_score_list):\n",
    "#     print(f'Fold {idx} Val Score: {val_score:.5f}')\n",
    "\n",
    "# oof_gt_df = oof_df[['samplename'] + label_list].copy()\n",
    "# oof_pred_df = oof_df[['samplename'] + pred_cols].copy()\n",
    "# oof_pred_df.columns = ['samplename'] + label_list\n",
    "# oof_score = score(oof_gt_df, oof_pred_df, 'samplename')\n",
    "# print(f'OOF Score: {oof_score:.5f}')\n",
    "\n",
    "#oof_df.to_csv(f\"{config.OUTPUT_DIR}/oof_pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(tokenized, split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LEADModelAtt(**nn_config).to(config.DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = torch.utils.data.DataLoader(\n",
    "        LEAD_Dataset(df.drop('fold', axis=1)),\n",
    "        batch_size=config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        #persistent_workers=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters = 2000\n",
    "eval_iters = 1000\n",
    "learning_rate = 3e-4\n",
    "# create a PyTorch optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for step in range(max_iters):\n",
    "    #print(iter)\n",
    "    # if iter % eval_iters == 0:\n",
    "    #     losses = estimate_loss()\n",
    "    #     print(f\"step: {iter}, train loss: {losses['train']:.3f}, val loss: {losses['val']:.3f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    #xb, yb = LEAD_Dataset(df.drop('fold', axis=1)).__getitem__(iter)\n",
    "\n",
    "    xb, yb = next(iter(train_dl))\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits = model.forward(xb.to('cuda').float(), yb.to('cuda').float())\n",
    "\n",
    "    loss = nn.MSELoss()(logits, yb.to('cuda').float())\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config.EPOCHS = 25  # max epochs\n",
    "#config.LR = 3e-4  # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir ./lightning_logs/version_0/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 2091745,
     "sourceId": 25954,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 3221581,
     "sourceId": 33246,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 5188730,
     "sourceId": 44224,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 8068726,
     "sourceId": 70203,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 1292430,
     "sourceId": 19596,
     "sourceType": "competition"
    },
    {
     "databundleVersionId": 8508280,
     "datasetId": 4979005,
     "sourceId": 8374380,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8528074,
     "datasetId": 4990143,
     "sourceId": 8393186,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 5267533,
     "datasetId": 3020983,
     "sourceId": 5195317,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8207598,
     "datasetId": 4776799,
     "sourceId": 8090934,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 8496617,
     "datasetId": 4970788,
     "sourceId": 8363310,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 152757,
     "datasetId": 3151,
     "sourceId": 142598,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 3680898,
     "datasetId": 2172852,
     "sourceId": 3627245,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 1520932,
     "datasetId": 726237,
     "sourceId": 1487019,
     "sourceType": "datasetVersion"
    },
    {
     "databundleVersionId": 1521030,
     "datasetId": 726312,
     "sourceId": 1487116,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 154204277,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 167220511,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
